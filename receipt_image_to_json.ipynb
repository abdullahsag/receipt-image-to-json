{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets"
      ],
      "metadata": {
        "id": "W9bWd0aKkUOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
        "import torch\n",
        "\n",
        "processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base-finetuned-cord-v2\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base-finetuned-cord-v2\")"
      ],
      "metadata": {
        "id": "Q6z_JmAikXA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "model.to(device)\n",
        "\n",
        "# prepare decoder inputs\n",
        "task_prompt = \"<s_cord-v2>\"\n",
        "decoder_input_ids = processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids"
      ],
      "metadata": {
        "id": "xT6gK8jFjRUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this part is to fetch receipt image to test\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"hf-internal-testing/example-documents\", split=\"test\")"
      ],
      "metadata": {
        "id": "rnfzfGQcjVts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get image\n",
        "image = dataset[2][\"image\"]\n",
        "# Display image\n",
        "display(dataset[2][\"image\"])"
      ],
      "metadata": {
        "id": "CJGa8KAWjhoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Can also pick self uploaded image to test\n",
        "# import cv2\n",
        "# image = cv2.imread(\"R1.jpg\")\n",
        "# #print(image)"
      ],
      "metadata": {
        "id": "Zogsq12Cj3Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
        "\n",
        "outputs = model.generate(\n",
        "  pixel_values.to(device),\n",
        "  decoder_input_ids = decoder_input_ids.to(device),\n",
        "  max_length = model.decoder.config.max_position_embeddings,\n",
        "  pad_token_id = processor.tokenizer.pad_token_id,\n",
        "  eos_token_id = processor.tokenizer.eos_token_id,\n",
        "  use_cache=True,\n",
        "  bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
        "  return_dict_in_generate=True,\n",
        ")\n",
        "\n",
        "sequence = processor.batch_decode(outputs.sequences)[0]\n",
        "sequence = sequence.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n",
        "sequence = re.sub(r\"<.*?>\", \"\", sequence, count=1).strip()  # remove first task start token\n",
        "json = processor.token2json(sequence)\n",
        "print(json)"
      ],
      "metadata": {
        "id": "KR8SZ5MrjivV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This is for Debug purpose or to download **model**"
      ],
      "metadata": {
        "id": "fo39_ztFjpp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check path of file (DEBUG)\n",
        "import os\n",
        "print(os.path.dirname(os.path.abspath(\"__file__\")))"
      ],
      "metadata": {
        "id": "AGxZ0leeFkof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdmTOR4MhHCB"
      },
      "source": [
        "# Save Model\n",
        "import pickle\n",
        "filename = 'image_receipt_processor_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r image_receipt_processor_model.sav.zip image_receipt_processor_model.sav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toK0ZXoJOo_v",
        "outputId": "5a5acb82-11b7-429c-c44a-0440856991da"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: image_receipt_processor_model.sav (deflated 7%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gN09lokhKuZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e95b07b7-a64d-4e42-f479-93d20247f736"
      },
      "source": [
        "# Check size of the model (DEBUG)\n",
        "import os\n",
        "gb = os.path.getsize(filename)/1024/1024\n",
        "print(gb)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768.9302835464478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download model\n",
        "from google.colab import files\n",
        "files.download(filename)"
      ],
      "metadata": {
        "id": "rf-j7FIRBkoE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}